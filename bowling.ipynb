{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "from a2c import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "torch.seed = RANDOM_STATE\n",
    "torch.manual_seed(torch.seed)\n",
    "np.random.seed(torch.seed)\n",
    "random.seed(torch.seed)\n",
    "\n",
    "ENV_NAME = 'ALE/Bowling-ram-v5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state: \n",
      "[ 71 255   0   0   0   0   0   0   0   0   0   0 255   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   8  15   0   0   0 170   0\n",
      "   1   0   0   0   1  12 184 247   0   0   6  16  19  13  22  16  10  25\n",
      "  19  13   7   7   5   5   3   3   3   1   1   1   1   0   0   0   0   0\n",
      "   0   0   0   0   0 136 216 132  38  88   0   0   1 255   0 255 128 255\n",
      "   0   0   0   0   0   0   0   2   2   0   8   8   0  34  34   0 136 136\n",
      "   0  34  34   0   8   8   0   2   2   0   0   0   0   0   0   0   0   0\n",
      "  66 243]\n",
      "Observation space: \n",
      "Box(0, 255, (128,), uint8)\n",
      "Action space: Discrete(6)\n",
      "Output from applying action 2 on environment:\n",
      "state:[ 75 255   0   1   0  16   4   4   4   4   4   4 255   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   8  15   0   2   0 170   0\n",
      "   1   0   0   0   1  12 184 247   0   0   0  16  19  13  22  16  10  25\n",
      "  19  13   7   7   5   5   3   3   3   1   1   1   1   0   0   0   0   0\n",
      "   0   0   0   0   0 136 216 132  38  88   0   0   1 255   0 255   0 134\n",
      "   0   0   0   0   0   0   0   2   2   0   8   8   0  34  34   0 136 136\n",
      "   0  34  34   0   8   8   0   2   2   0   0   0   0   0   0   0   0   0\n",
      "  52   7]\n",
      "reward: 0.0\n",
      "done: False\n",
      "truncated: False\n",
      "info: {'lives': 0, 'episode_frame_number': 4, 'frame_number': 4}\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "\n",
    "state, _ = env.reset()\n",
    "print(f\"Initial state: \\n{state}\")\n",
    "print(f\"Observation space: \\n{env.observation_space}\")\n",
    "print(f\"Action space: {env.action_space}\")\n",
    "\n",
    "a = env.action_space.sample()\n",
    "event = env.step(a)\n",
    "print('Output from applying action {} on environment:\\nstate:'.format(a) \\\n",
    "      + '{}\\nreward: {}\\ndone: {}\\ntruncated: {}\\ninfo: {}'.format(*event))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining A2CBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2CBatch(A2C):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        # Overrides the loss function for the actor. Since we are trying batch processing, we need to sum up the losses\n",
    "        self.actorLossFun = lambda probs, advantage: - \\\n",
    "            1 * torch.sum(torch.log(probs) * advantage)\n",
    "\n",
    "    # Trains the agent            \n",
    "    def train(self, epochs=200, gamma=0.99, memory=500, batch=200):\n",
    "        # Stores the info from the training process\n",
    "        info = {}\n",
    "        # Stores the total reward or scores per epoch\n",
    "        scores = []\n",
    "        # The replay buffer for Q-learning with experience replay\n",
    "        replay = deque(maxlen=memory)\n",
    "        for e in range(epochs):\n",
    "            # Resets the environment per epoch\n",
    "            state_, _ = self.env.reset()\n",
    "            # A flag to check if an episode has ended\n",
    "            done = False\n",
    "            # Stores the score per episode\n",
    "            score = 0\n",
    "            # Maximum number of allowed moves per episode\n",
    "            maxMoves = 200\n",
    "            # Stores the information per move in an episode\n",
    "            iterations = []            \n",
    "            # Continue the episode until it ends or the maximum number of episodes has expired\n",
    "            while not done and maxMoves > 0:\n",
    "                # Decrement the number of allowed moves\n",
    "                maxMoves -= 1\n",
    "                # Calculate the probs. for the actions for a given state\n",
    "                policy = self.actor(torch.from_numpy(\n",
    "                    state_).float())\n",
    "                # Choose an action based on their probs.\n",
    "                action = np.random.choice(\n",
    "                    self.numActionSpace, p=policy.detach().numpy())\n",
    "                # Executes an action to the environment\n",
    "                nextState_, reward, done, truncated, _ = self.env.step(action)\n",
    "                # Updates the rewards for the episode\n",
    "                score += reward\n",
    "                # Calculates the value of the current state\n",
    "                value = self.critic(torch.from_numpy(state_).float())\n",
    "                # Calculate the value of the next state\n",
    "                nextValue = torch.Tensor([0.0]) if done else self.critic(\n",
    "                    torch.from_numpy(nextState_).float())\n",
    "                \n",
    "                # Add the experience to the buffer\n",
    "                replay.append((state_, reward, nextValue.item()))\n",
    "                # Add the episode step info\n",
    "                iterations.append(\n",
    "                    (state_, action, reward, nextValue.item() - value.item())) \n",
    "                # Assign next state as current state\n",
    "                state_ = nextState_\n",
    "\n",
    "            # After each episode update the actor model\n",
    "            # Policy Loss\n",
    "            iterations_ = np.asarray(iterations, dtype=object)  \n",
    "            # Calculate the advantage\n",
    "            advantage = torch.Tensor(list(iterations_[:, 2])).float() + torch.pow(gamma, torch.arange(\n",
    "                len(iterations_)).flip(dims=(0, )).float()) * torch.Tensor(list(iterations_[:, 3])).float()\n",
    "\n",
    "            # Store the state info as a batch of states\n",
    "            stateBatch = torch.stack([torch.from_numpy(s).float()\n",
    "                                      for s in iterations_[:, 0]])\n",
    "            # Store the action info as a batch of actions    \n",
    "            actionBatch = torch.Tensor(list(iterations_[:, 1]))\n",
    "            # Feed the state batch to the actor model to calculate the probs of actions for each state in the batch\n",
    "            policy = self.actor(stateBatch)\n",
    "            # Gets the probs of actions actually performed for each state\n",
    "            probs = policy.gather(\n",
    "                dim=1, index=actionBatch.long().unsqueeze(dim=1)).squeeze()\n",
    "\n",
    "            # Policy Loss\n",
    "            actorLoss = self.actorLossFun(probs, advantage)\n",
    "            #Backpropagate policy\n",
    "            self.actorOptim.zero_grad()\n",
    "            actorLoss.backward()\n",
    "            self.actorOptim.step()\n",
    "\n",
    "            # Update the value function if the size of the replay buffer is larger than the specified batch size\n",
    "            if (len(replay) > batch):\n",
    "                # Select a set of random indices to be chosen from the replay buffer \n",
    "                indices = np.random.choice(len(replay), size=batch)\n",
    "                # Extract the experiences from the replay buffer\n",
    "                replay_ = np.asarray(replay, dtype=object)[indices, :]  \n",
    "                # Create a state batch with the excted experiences\n",
    "                stateBatch = torch.stack([torch.from_numpy(s).float()\n",
    "                                          for s in replay_[:, 0]])\n",
    "                # Calculate the value for the extracted states                                        \n",
    "                value = self.critic(stateBatch)                                                \n",
    "                \n",
    "                # Value Loss\n",
    "                criticLoss = self.criticLossFun(\n",
    "                    value, torch.Tensor(list(replay_[\n",
    "                        :, 1] + gamma * replay_[:, 2])).float())\n",
    "                                \n",
    "                #Backpropagate value\n",
    "                self.criticOptim.zero_grad()\n",
    "                criticLoss.backward()\n",
    "                self.criticOptim.step()            \n",
    "                \n",
    "            # Store the total score for the episode\n",
    "            scores.append(score)\n",
    "\n",
    "            # Print the progress\n",
    "            if e % np.round(epochs/10) == 0:\n",
    "                print('episode: {:d}, score: {:.2f}'.format(e, scores[e]))\n",
    "            info[e] = scores[e]\n",
    "\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, score: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Cours\\UiS\\RL\\Project\\reinforcement-learning\\venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([200])) that is different to the input size (torch.Size([200, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 200, score: 0.00\n",
      "episode: 400, score: 0.00\n",
      "episode: 600, score: 0.00\n",
      "episode: 800, score: 0.00\n",
      "episode: 1000, score: 0.00\n",
      "episode: 1200, score: 0.00\n",
      "episode: 1400, score: 0.00\n",
      "episode: 1600, score: 0.00\n",
      "episode: 1800, score: 0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHHCAYAAACvJxw8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0FElEQVR4nO3de1xVVf7/8TcoHHHyQCpCGOBd8JIXFESbLCHRnNSySR1nvGQ606hdNDOttOw7Q43f0srUZr5TjmOm2TTOTJqlqNkoecFLecPL18RUwBvgFdCzfn/083w7gUtEEA7zej4e55GsvdY+n3U2nP1u73328THGGAEAAKBYvhVdAAAAQGVGWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAfBa33zzjR566CFFRkaqRo0aql+/vu6991699dZbFV0agCrEh++GA+CN1q9fr3vuuUcREREaMmSIQkNDdfjwYX311Vc6cOCA9u/fX9ElAqgiCEsAvFKvXr20adMm7d27V0FBQR7LsrOzVa9evZtSx/nz51WzZs2b8lwAKgan4QB4pQMHDqhly5ZFgpKkIkFp/vz5io2NVc2aNXXrrbfqrrvu0ueff+7RZ9asWWrZsqUcDofCwsI0atQo5eTkePS5++671apVK6Wlpemuu+5SzZo1NWnSJElSfn6+pkyZoiZNmsjhcCg8PFzPPPOM8vPzPdaxYsUK3XnnnQoKCtItt9yi5s2bu9cBoHKqXtEFAEBpREZGKjU1VTt27FCrVq2u2u+ll17Siy++qM6dO2vq1Kny9/fXhg0btGrVKnXv3l2S9OKLL+qll15SYmKiHnvsMaWnp2v27NnatGmT1q1bJz8/P/f6Tp48qZ49e2rAgAH65S9/qZCQELlcLvXu3Vv//ve/NXLkSEVHR+ubb77R9OnTtXfvXi1ZskSStHPnTv3sZz/THXfcoalTp8rhcGj//v1at25dub5WAG6QAQAv9Pnnn5tq1aqZatWqmfj4ePPMM8+Yzz77zBQUFLj77Nu3z/j6+poHHnjAXL582WO8y+UyxhiTnZ1t/P39Tffu3T36zJw500gy7777rruta9euRpKZM2eOx7r++te/Gl9fX/Pll196tM+ZM8dIMuvWrTPGGDN9+nQjyRw/frxsXgQANwWn4QB4pXvvvVepqanq3bu3tm/frj/84Q9KSkpS/fr19c9//lOStGTJErlcLk2ePFm+vp5vdz4+PpKklStXqqCgQE8++aRHnxEjRsjpdGrp0qUe4xwOh4YNG+bRtnjxYkVHRysqKkonTpxwP7p16yZJWr16tSS5Txn+4x//kMvlKrsXA0C5IiwB8FodO3bUxx9/rNOnT2vjxo2aOHGizpw5o4ceeki7du3SgQMH5OvrqxYtWlx1HYcOHZIkNW/e3KPd399fjRo1ci+/on79+vL39/do27dvn3bu3Kng4GCPR7NmzSR9f8G5JPXv319dunTRo48+qpCQEA0YMEAffvghwQmo5LhmCYDX8/f3V8eOHdWxY0c1a9ZMw4YN0+LFi8vluQICAoq0uVwutW7dWq+//nqxY8LDw91j165dq9WrV2vp0qVavny5Fi1apG7duunzzz9XtWrVyqVmADeGsASgSunQoYMk6dixY2rSpIlcLpd27dqltm3bFts/MjJSkpSenq5GjRq52wsKCnTw4EElJiZe8zkbN26s7du3KyEhwX1672p8fX2VkJCghIQEvf766/r973+v5557TqtXry7RcwG4+TgNB8ArrV69WqaY28QtW7ZM0ven1fr27StfX19NnTq1yKmuK2MTExPl7++vN99802N9f/7zn5Wbm6tevXpds5aHH35YR44c0Z/+9Kciyy5cuKBz585Jkk6dOlVk+ZUQ9+NbDACoPLgpJQCv1KpVK50/f14PPPCAoqKiVFBQoPXr12vRokUKDw/X1q1bFRQUpMmTJ+vll19W586d9eCDD8rhcGjTpk0KCwtTcnKypP+7dUD37t3Vu3dvpaena9asWWrfvr3HrQPuvvtunThxQjt27PCoxeVy6f7779enn37qvi7p8uXL2rNnjz788EN99tln6tChg5588kmtXbtWvXr1UmRkpLKzszVr1iz5+Phox44dCgwMvOmvI4ASqNDP4gFAKX366afmkUceMVFRUeaWW24x/v7+pkmTJmbMmDEmKyvLo++7775r2rVrZxwOh7n11ltN165dzYoVKzz6zJw500RFRRk/Pz8TEhJiHnvsMXP69GmPPl27djUtW7Ystp6CggLz6quvmpYtW7qfJyYmxrz00ksmNzfXGGNMSkqK6dOnjwkLCzP+/v4mLCzMDBw40Ozdu7fsXhgAZY4jSwAAABZcswQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAu+7qQMuFwuHT16VLVq1brmVx0AAIDKwRijM2fOKCwsTL6+Vz9+RFgqA0ePHnV/USYAAPAuhw8f1u23337V5YSlMlCrVi1J37/YTqezgqsBAAAlkZeXp/DwcPd+/GoIS2Xgyqk3p9NJWAIAwMtc6xIaLvAGAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALLwuLL399ttq0KCBatSoobi4OG3cuNHaf/HixYqKilKNGjXUunVrLVu27Kp9f/Ob38jHx0czZswo46oBAIC38qqwtGjRIo0dO1ZTpkzRli1b1KZNGyUlJSk7O7vY/uvXr9fAgQM1fPhwbd26VX379lXfvn21Y8eOIn3//ve/66uvvlJYWFh5TwMAAHgRrwpLr7/+ukaMGKFhw4apRYsWmjNnjmrWrKl333232P5vvPGGevToofHjxys6Olovv/yy2rdvr5kzZ3r0O3LkiMaMGaP3339ffn5+N2MqAADAS3hNWCooKFBaWpoSExPdbb6+vkpMTFRqamqxY1JTUz36S1JSUpJHf5fLpV/96lcaP368WrZsWT7FAwAAr1W9ogsoqRMnTujy5csKCQnxaA8JCdGePXuKHZOZmVls/8zMTPfPr776qqpXr67HH3+8xLXk5+crPz/f/XNeXl6JxwIAAO/iNUeWykNaWpreeOMNzZ07Vz4+PiUel5ycrMDAQPcjPDy8HKsEAAAVyWvCUt26dVWtWjVlZWV5tGdlZSk0NLTYMaGhodb+X375pbKzsxUREaHq1aurevXqOnTokMaNG6cGDRpctZaJEycqNzfX/Th8+PCNTQ4AAFRaXhOW/P39FRMTo5SUFHeby+VSSkqK4uPjix0THx/v0V+SVqxY4e7/q1/9Sl9//bW2bdvmfoSFhWn8+PH67LPPrlqLw+GQ0+n0eAAAgKrJa65ZkqSxY8dqyJAh6tChg2JjYzVjxgydO3dOw4YNkyQNHjxY9evXV3JysiTpiSeeUNeuXfXaa6+pV69eWrhwoTZv3qw//vGPkqQ6deqoTp06Hs/h5+en0NBQNW/e/OZODgAAVEpeFZb69++v48ePa/LkycrMzFTbtm21fPly90XcGRkZ8vX9v4NlnTt31oIFC/T8889r0qRJatq0qZYsWaJWrVpV1BQAAICX8THGmIouwtvl5eUpMDBQubm5nJIDAMBLlHT/7TXXLAEAAFQEwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABZeF5befvttNWjQQDVq1FBcXJw2btxo7b948WJFRUWpRo0aat26tZYtW+ZeVlhYqAkTJqh169b6yU9+orCwMA0ePFhHjx4t72kAAAAv4VVhadGiRRo7dqymTJmiLVu2qE2bNkpKSlJ2dnax/devX6+BAwdq+PDh2rp1q/r27au+fftqx44dkqTz589ry5YteuGFF7RlyxZ9/PHHSk9PV+/evW/mtAAAQCXmY4wxFV1EScXFxaljx46aOXOmJMnlcik8PFxjxozRs88+W6R///79de7cOX3yySfutk6dOqlt27aaM2dOsc+xadMmxcbG6tChQ4qIiChRXXl5eQoMDFRubq6cTmcpZgYAAG62ku6/vebIUkFBgdLS0pSYmOhu8/X1VWJiolJTU4sdk5qa6tFfkpKSkq7aX5Jyc3Pl4+OjoKCgMqkbAAB4t+oVXUBJnThxQpcvX1ZISIhHe0hIiPbs2VPsmMzMzGL7Z2ZmFtv/4sWLmjBhggYOHGhNmPn5+crPz3f/nJeXV9JpAAAAL+M1R5bKW2FhoR5++GEZYzR79mxr3+TkZAUGBrof4eHhN6lKAABws3lNWKpbt66qVaumrKwsj/asrCyFhoYWOyY0NLRE/a8EpUOHDmnFihXXvO5o4sSJys3NdT8OHz5cihkBAABv4DVhyd/fXzExMUpJSXG3uVwupaSkKD4+vtgx8fHxHv0lacWKFR79rwSlffv2aeXKlapTp841a3E4HHI6nR4PAABQNXnNNUuSNHbsWA0ZMkQdOnRQbGysZsyYoXPnzmnYsGGSpMGDB6t+/fpKTk6WJD3xxBPq2rWrXnvtNfXq1UsLFy7U5s2b9cc//lHS90HpoYce0pYtW/TJJ5/o8uXL7uuZateuLX9//4qZKAAAqDS8Kiz1799fx48f1+TJk5WZmam2bdtq+fLl7ou4MzIy5Ov7fwfLOnfurAULFuj555/XpEmT1LRpUy1ZskStWrWSJB05ckT//Oc/JUlt27b1eK7Vq1fr7rvvvinzAgAAlZdX3WepsuI+SwAAeJ8qd58lAACAikBYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABalDks5OTn6n//5H02cOFGnTp2SJG3ZskVHjhwps+IAAAAqWvXSDPr666+VmJiowMBAffvttxoxYoRq166tjz/+WBkZGZo3b15Z1wkAAFAhSnVkaezYsRo6dKj27dunGjVquNvvu+8+rV27tsyKAwAAqGilCkubNm3Sr3/96yLt9evXV2Zm5g0XBQAAUFmUKiw5HA7l5eUVad+7d6+Cg4NvuCgAAIDKolRhqXfv3po6daoKCwslST4+PsrIyNCECRPUr1+/Mi0QAACgIpUqLL322ms6e/as6tWrpwsXLqhr165q0qSJatWqpd/97ndlXSMAAECFKdWn4QIDA7VixQqtW7dO27dv19mzZ9W+fXslJiaWdX0AAAAV6rrDUmFhoQICArRt2zZ16dJFXbp0KY+6AAAAKoXrPg3n5+eniIgIXb58uTzqAQAAqFRKdc3Sc889p0mTJrnv3A0AAFBVleqapZkzZ2r//v0KCwtTZGSkfvKTn3gs37JlS5kUBwAAUNFKFZb69u1bxmWU3Ntvv61p06YpMzNTbdq00VtvvaXY2Nir9l+8eLFeeOEFffvtt2ratKleffVV3Xfffe7lxhhNmTJFf/rTn5STk6MuXbpo9uzZatq06c2YDgAAqOR8jDGmoosoqUWLFmnw4MGaM2eO4uLiNGPGDC1evFjp6emqV69ekf7r16/XXXfdpeTkZP3sZz/TggUL9Oqrr2rLli1q1aqVJOnVV19VcnKy/vKXv6hhw4Z64YUX9M0332jXrl0eX+Vik5eXp8DAQOXm5srpdJbpnAEAQPko6f77hsJSWlqadu/eLUlq2bKl2rVrV9pVlUhcXJw6duyomTNnSpJcLpfCw8M1ZswYPfvss0X69+/fX+fOndMnn3zibuvUqZPatm2rOXPmyBijsLAwjRs3Tk8//bQkKTc3VyEhIZo7d64GDBhQorrKKyx9d/p8ma0LAABvVj8oQD4+PmW6zpLuv0t1Gi47O1sDBgzQmjVrFBQUJEnKycnRPffco4ULF5bLV54UFBQoLS1NEydOdLf5+voqMTFRqampxY5JTU3V2LFjPdqSkpK0ZMkSSdLBgweVmZnpcX+owMBAxcXFKTU19aphKT8/X/n5+e6fi/vql7LQ7bUvVHDJVS7rBgDAm+z9r57yr162YamkShWWxowZozNnzmjnzp2Kjo6WJO3atUtDhgzR448/rg8++KBMi5SkEydO6PLlywoJCfFoDwkJ0Z49e4odk5mZWWz/K1/2e+W/tj7FSU5O1ksvvXTdc7hejuq+qphfCwAAcEWpwtLy5cu1cuVKd1CSpBYtWujtt99W9+7dy6y4ymrixIkeR6zy8vIUHh5e5s/zzYtJZb5OAABwfUp1nyWXyyU/P78i7X5+fnK5yue0Ud26dVWtWjVlZWV5tGdlZSk0NLTYMaGhodb+V/57PeuUJIfDIafT6fEAAABVU6nCUrdu3fTEE0/o6NGj7rYjR47oqaeeUkJCQpkV90P+/v6KiYlRSkqKu83lciklJUXx8fHFjomPj/foL0krVqxw92/YsKFCQ0M9+uTl5WnDhg1XXScAAPjPUuqbUvbu3VsNGjRwn346fPiwWrVqpfnz55dpgT80duxYDRkyRB06dFBsbKxmzJihc+fOadiwYZKkwYMHq379+kpOTpYkPfHEE+ratatee+019erVSwsXLtTmzZv1xz/+UZLk4+OjJ598Uv/1X/+lpk2bum8dEBYWVqH3kgIAAJVHqcJSeHi4tmzZopUrV7ovro6Ojvb4VFl56N+/v44fP67JkycrMzNTbdu21fLly90XaGdkZMjX9/8OlnXu3FkLFizQ888/r0mTJqlp06ZasmSJ+x5LkvTMM8/o3LlzGjlypHJycnTnnXdq+fLlJb7HEgAAqNq86qaUlRU3pQQAwPuUdP9dqmuWHn/8cb355ptF2mfOnKknn3yyNKsEAAColEoVlv72t7+pS5cuRdo7d+6sjz766IaLAgAAqCxKFZZOnjypwMDAIu1Op1MnTpy44aIAAAAqi1KFpSZNmmj58uVF2j/99FM1atTohosCAACoLEr1abixY8dq9OjROn78uLp16yZJSklJ0X//93/rjTfeKNMCAQAAKlKpwtIjjzyi/Px8/e53v9PLL78s6fsbPM6ZM0eDBw8u0wIBAAAqUqlOw124cEFDhgzRd999p6ysLH399dcaPXp0kS+kBQAA8HalCkt9+vTRvHnzJH3/fXCJiYl6/fXX1bdvX82ePbtMCwQAAKhIpQpLW7Zs0U9/+lNJ0kcffaSQkBAdOnRI8+bNK/b+SwAAAN6qVGHp/PnzqlWrliTp888/14MPPihfX1916tRJhw4dKtMCAQAAKlKpbx2wZMkSHT58WJ999pm6d+8uScrOzubrPgAAQJVSqrA0efJkPf3002rQoIHi4uIUHx8v6fujTO3atSvTAgEAACpSqb9INzMzU8eOHVObNm3k6/t95tq4caOcTqeioqLKtMjKji/SBQDA+5R0/12q+yxJUmhoqEJDQz3aYmNjS7s6AACASqlUp+EAAAD+UxCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACy8JiydOnVKgwYNktPpVFBQkIYPH66zZ89ax1y8eFGjRo1SnTp1dMstt6hfv37KyspyL9++fbsGDhyo8PBwBQQEKDo6Wm+88UZ5TwUAAHgRrwlLgwYN0s6dO7VixQp98sknWrt2rUaOHGkd89RTT+lf//qXFi9erC+++EJHjx7Vgw8+6F6elpamevXqaf78+dq5c6eee+45TZw4UTNnzizv6QAAAC/hY4wxFV3EtezevVstWrTQpk2b1KFDB0nS8uXLdd999+m7775TWFhYkTG5ubkKDg7WggUL9NBDD0mS9uzZo+joaKWmpqpTp07FPteoUaO0e/durVq1qsT15eXlKTAwULm5uXI6naWYIQAAuNlKuv/2iiNLqampCgoKcgclSUpMTJSvr682bNhQ7Ji0tDQVFhYqMTHR3RYVFaWIiAilpqZe9blyc3NVu3Ztaz35+fnKy8vzeAAAgKrJK8JSZmam6tWr59FWvXp11a5dW5mZmVcd4+/vr6CgII/2kJCQq45Zv369Fi1adM3Te8nJyQoMDHQ/wsPDSz4ZAADgVSo0LD377LPy8fGxPvbs2XNTatmxY4f69OmjKVOmqHv37ta+EydOVG5urvtx+PDhm1IjAAC4+apX5JOPGzdOQ4cOtfZp1KiRQkNDlZ2d7dF+6dIlnTp1SqGhocWOCw0NVUFBgXJycjyOLmVlZRUZs2vXLiUkJGjkyJF6/vnnr1m3w+GQw+G4Zj8AAOD9KjQsBQcHKzg4+Jr94uPjlZOTo7S0NMXExEiSVq1aJZfLpbi4uGLHxMTEyM/PTykpKerXr58kKT09XRkZGYqPj3f327lzp7p166YhQ4bod7/7XRnMCgAAVCVe8Wk4SerZs6eysrI0Z84cFRYWatiwYerQoYMWLFggSTpy5IgSEhI0b948xcbGSpIee+wxLVu2THPnzpXT6dSYMWMkfX9tkvT9qbdu3bopKSlJ06ZNcz9XtWrVShTiruDTcAAAeJ+S7r8r9MjS9Xj//fc1evRoJSQkyNfXV/369dObb77pXl5YWKj09HSdP3/e3TZ9+nR33/z8fCUlJWnWrFnu5R999JGOHz+u+fPna/78+e72yMhIffvttzdlXgAAoHLzmiNLlRlHlgAA8D5V6j5LAAAAFYWwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACAhdeEpVOnTmnQoEFyOp0KCgrS8OHDdfbsWeuYixcvatSoUapTp45uueUW9evXT1lZWcX2PXnypG6//Xb5+PgoJyenHGYAAAC8kdeEpUGDBmnnzp1asWKFPvnkE61du1YjR460jnnqqaf0r3/9S4sXL9YXX3yho0eP6sEHHyy27/Dhw3XHHXeUR+kAAMCL+RhjTEUXcS27d+9WixYttGnTJnXo0EGStHz5ct1333367rvvFBYWVmRMbm6ugoODtWDBAj300EOSpD179ig6Olqpqanq1KmTu+/s2bO1aNEiTZ48WQkJCTp9+rSCgoJKXF9eXp4CAwOVm5srp9N5Y5MFAAA3RUn3315xZCk1NVVBQUHuoCRJiYmJ8vX11YYNG4odk5aWpsLCQiUmJrrboqKiFBERodTUVHfbrl27NHXqVM2bN0++viV7OfLz85WXl+fxAAAAVZNXhKXMzEzVq1fPo6169eqqXbu2MjMzrzrG39+/yBGikJAQ95j8/HwNHDhQ06ZNU0RERInrSU5OVmBgoPsRHh5+fRMCAABeo0LD0rPPPisfHx/rY8+ePeX2/BMnTlR0dLR++ctfXve43Nxc9+Pw4cPlVCEAAKho1SvyyceNG6ehQ4da+zRq1EihoaHKzs72aL906ZJOnTql0NDQYseFhoaqoKBAOTk5HkeXsrKy3GNWrVqlb775Rh999JEk6crlW3Xr1tVzzz2nl156qdh1OxwOORyOkkwRAAB4uQoNS8HBwQoODr5mv/j4eOXk5CgtLU0xMTGSvg86LpdLcXFxxY6JiYmRn5+fUlJS1K9fP0lSenq6MjIyFB8fL0n629/+pgsXLrjHbNq0SY888oi+/PJLNW7c+EanBwAAqoAKDUslFR0drR49emjEiBGaM2eOCgsLNXr0aA0YMMD9SbgjR44oISFB8+bNU2xsrAIDAzV8+HCNHTtWtWvXltPp1JgxYxQfH+/+JNyPA9GJEyfcz3c9n4YDAABVl1eEJUl6//33NXr0aCUkJMjX11f9+vXTm2++6V5eWFio9PR0nT9/3t02ffp0d9/8/HwlJSVp1qxZFVE+AADwUl5xn6XKjvssAQDgfarUfZYAAAAqCmEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYEFYAgAAsCAsAQAAWBCWAAAALAhLAAAAFoQlAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsAAAAWhCUAAAALwhIAAIAFYQkAAMCCsAQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYFG9oguoCowxkqS8vLwKrgQAAJTUlf32lf341RCWysCZM2ckSeHh4RVcCQAAuF5nzpxRYGDgVZf7mGvFKVyTy+XS0aNHVatWLfn4+JTZevPy8hQeHq7Dhw/L6XSW2Xori6o+P6nqz7Gqz0+q+nNkft6vqs+xPOdnjNGZM2cUFhYmX9+rX5nEkaUy4Ovrq9tvv73c1u90OqvkH8AVVX1+UtWfY1Wfn1T158j8vF9Vn2N5zc92ROkKLvAGAACwICwBAABYEJYqMYfDoSlTpsjhcFR0KeWiqs9PqvpzrOrzk6r+HJmf96vqc6wM8+MCbwAAAAuOLAEAAFgQlgAAACwISwAAABaEJQAAAAvCUiX29ttvq0GDBqpRo4bi4uK0cePGii7pmpKTk9WxY0fVqlVL9erVU9++fZWenu7R5+6775aPj4/H4ze/+Y1Hn4yMDPXq1Us1a9ZUvXr1NH78eF26dOlmTuWqXnzxxSL1R0VFuZdfvHhRo0aNUp06dXTLLbeoX79+ysrK8lhHZZ5fgwYNiszPx8dHo0aNkuSd22/t2rW6//77FRYWJh8fHy1ZssRjuTFGkydP1m233aaAgAAlJiZq3759Hn1OnTqlQYMGyel0KigoSMOHD9fZs2c9+nz99df66U9/qho1aig8PFx/+MMfyntqkuzzKyws1IQJE9S6dWv95Cc/UVhYmAYPHqyjR496rKO47f7KK6949KmM85OkoUOHFqm9R48eHn0q8/aTrj3H4v4mfXx8NG3aNHefyrwNS7JvKKv3zjVr1qh9+/ZyOBxq0qSJ5s6de+MTMKiUFi5caPz9/c27775rdu7caUaMGGGCgoJMVlZWRZdmlZSUZN577z2zY8cOs23bNnPfffeZiIgIc/bsWXefrl27mhEjRphjx465H7m5ue7lly5dMq1atTKJiYlm69atZtmyZaZu3bpm4sSJFTGlIqZMmWJatmzpUf/x48fdy3/zm9+Y8PBwk5KSYjZv3mw6depkOnfu7F5e2eeXnZ3tMbcVK1YYSWb16tXGGO/cfsuWLTPPPfec+fjjj40k8/e//91j+SuvvGICAwPNkiVLzPbt203v3r1Nw4YNzYULF9x9evToYdq0aWO++uor8+WXX5omTZqYgQMHupfn5uaakJAQM2jQILNjxw7zwQcfmICAAPPOO+9U6PxycnJMYmKiWbRokdmzZ49JTU01sbGxJiYmxmMdkZGRZurUqR7b9Yd/t5V1fsYYM2TIENOjRw+P2k+dOuXRpzJvP2OuPccfzu3YsWPm3XffNT4+PubAgQPuPpV5G5Zk31AW753/+7//a2rWrGnGjh1rdu3aZd566y1TrVo1s3z58huqn7BUScXGxppRo0a5f758+bIJCwszycnJFVjV9cvOzjaSzBdffOFu69q1q3niiSeuOmbZsmXG19fXZGZmuttmz55tnE6nyc/PL89yS2TKlCmmTZs2xS7Lyckxfn5+ZvHixe623bt3G0kmNTXVGFP55/djTzzxhGncuLFxuVzGGO/ffj/eEblcLhMaGmqmTZvmbsvJyTEOh8N88MEHxhhjdu3aZSSZTZs2uft8+umnxsfHxxw5csQYY8ysWbPMrbfe6jHHCRMmmObNm5fzjDwVt6P9sY0bNxpJ5tChQ+62yMhIM3369KuOqczzGzJkiOnTp89Vx3jT9jOmZNuwT58+plu3bh5t3rINjSm6byir985nnnnGtGzZ0uO5+vfvb5KSkm6oXk7DVUIFBQVKS0tTYmKiu83X11eJiYlKTU2twMquX25uriSpdu3aHu3vv/++6tatq1atWmnixIk6f/68e1lqaqpat26tkJAQd1tSUpLy8vK0c+fOm1P4Nezbt09hYWFq1KiRBg0apIyMDElSWlqaCgsLPbZdVFSUIiIi3NvOG+Z3RUFBgebPn69HHnnE40uivX37/dDBgweVmZnpsc0CAwMVFxfnsc2CgoLUoUMHd5/ExET5+vpqw4YN7j533XWX/P393X2SkpKUnp6u06dP36TZlExubq58fHwUFBTk0f7KK6+oTp06ateunaZNm+ZxeqOyz2/NmjWqV6+emjdvrscee0wnT550L6tq2y8rK0tLly7V8OHDiyzzlm34431DWb13pqameqzjSp8b3XfyRbqV0IkTJ3T58mWPXwhJCgkJ0Z49eyqoquvncrn05JNPqkuXLmrVqpW7/Re/+IUiIyMVFhamr7/+WhMmTFB6ero+/vhjSVJmZmaxc7+yrKLFxcVp7ty5at68uY4dO6aXXnpJP/3pT7Vjxw5lZmbK39+/yE4oJCTEXXtln98PLVmyRDk5ORo6dKi7zdu3349dqam4mn+4zerVq+exvHr16qpdu7ZHn4YNGxZZx5Vlt956a7nUf70uXryoCRMmaODAgR5fSvr444+rffv2ql27ttavX6+JEyfq2LFjev311yVV7vn16NFDDz74oBo2bKgDBw5o0qRJ6tmzp1JTU1WtWrUqtf0k6S9/+Ytq1aqlBx980KPdW7ZhcfuGsnrvvFqfvLw8XbhwQQEBAaWqmbCEcjNq1Cjt2LFD//73vz3aR44c6f5369atddtttykhIUEHDhxQ48aNb3aZ161nz57uf99xxx2Ki4tTZGSkPvzww1L/IVZWf/7zn9WzZ0+FhYW527x9+/0nKyws1MMPPyxjjGbPnu2xbOzYse5/33HHHfL399evf/1rJScnV/qv0RgwYID7361bt9Ydd9yhxo0ba82aNUpISKjAysrHu+++q0GDBqlGjRoe7d6yDa+2b6jMOA1XCdWtW1fVqlUr8imArKwshYaGVlBV12f06NH65JNPtHr1at1+++3WvnFxcZKk/fv3S5JCQ0OLnfuVZZVNUFCQmjVrpv379ys0NFQFBQXKycnx6PPDbect8zt06JBWrlypRx991NrP27fflZpsf2+hoaHKzs72WH7p0iWdOnXKa7brlaB06NAhrVixwuOoUnHi4uJ06dIlffvtt5Iq//x+qFGjRqpbt67H76S3b78rvvzyS6Wnp1/z71KqnNvwavuGsnrvvFofp9N5Q/8zS1iqhPz9/RUTE6OUlBR3m8vlUkpKiuLj4yuwsmszxmj06NH6+9//rlWrVhU55Fucbdu2SZJuu+02SVJ8fLy++eYbjze3K2/uLVq0KJe6b8TZs2d14MAB3XbbbYqJiZGfn5/HtktPT1dGRoZ723nL/N577z3Vq1dPvXr1svbz9u3XsGFDhYaGemyzvLw8bdiwwWOb5eTkKC0tzd1n1apVcrlc7rAYHx+vtWvXqrCw0N1nxYoVat68eYWfwrkSlPbt26eVK1eqTp061xyzbds2+fr6uk9fVeb5/dh3332nkydPevxOevP2+6E///nPiomJUZs2ba7ZtzJtw2vtG8rqvTM+Pt5jHVf63PC+84YuD0e5WbhwoXE4HGbu3Llm165dZuTIkSYoKMjjUwCV0WOPPWYCAwPNmjVrPD6+ev78eWOMMfv37zdTp041mzdvNgcPHjT/+Mc/TKNGjcxdd93lXseVj4d2797dbNu2zSxfvtwEBwdXmo/Wjxs3zqxZs8YcPHjQrFu3ziQmJpq6deua7OxsY8z3H3+NiIgwq1atMps3bzbx8fEmPj7ePb6yz8+Y7z99GRERYSZMmODR7q3b78yZM2br1q1m69atRpJ5/fXXzdatW92fBnvllVdMUFCQ+cc//mG+/vpr06dPn2JvHdCuXTuzYcMG8+9//9s0bdrU46PnOTk5JiQkxPzqV78yO3bsMAsXLjQ1a9a8KR/Lts2voKDA9O7d29x+++1m27ZtHn+XVz5BtH79ejN9+nSzbds2c+DAATN//nwTHBxsBg8eXOnnd+bMGfP000+b1NRUc/DgQbNy5UrTvn1707RpU3Px4kX3Oirz9rvWHK/Izc01NWvWNLNnzy4yvrJvw2vtG4wpm/fOK7cOGD9+vNm9e7d5++23uXVAVffWW2+ZiIgI4+/vb2JjY81XX31V0SVdk6RiH++9954xxpiMjAxz1113mdq1axuHw2GaNGlixo8f73GfHmOM+fbbb03Pnj1NQECAqVu3rhk3bpwpLCysgBkV1b9/f3PbbbcZf39/U79+fdO/f3+zf/9+9/ILFy6Y3/72t+bWW281NWvWNA888IA5duyYxzoq8/yMMeazzz4zkkx6erpHu7duv9WrVxf7ezlkyBBjzPe3D3jhhRdMSEiIcTgcJiEhocjcT548aQYOHGhuueUW43Q6zbBhw8yZM2c8+mzfvt3ceeedxuFwmPr165tXXnmlwud38ODBq/5dXrl3VlpamomLizOBgYGmRo0aJjo62vz+97/3CBuVdX7nz5833bt3N8HBwcbPz89ERkaaESNGFPkfy8q8/a41xyveeecdExAQYHJycoqMr+zb8Fr7BmPK7r1z9erVpm3btsbf3980atTI4zlKy+f/TwIAAADF4JolAAAAC8ISAACABWEJAADAgrAEAABgQVgCAACwICwBAABYEJYAAAAsCEsA/mPNnTu3yLecl7UGDRpoxowZ5focAMoXYQnAf6z+/ftr7969FV0GgEquekUXAAAVJSAg4Ia+iRzAfwaOLAHwWi6XS8nJyWrYsKECAgLUpk0bffTRR5KkNWvWyMfHR0uXLtUdd9yhGjVqqFOnTtqxY4d7/I9Pw23fvl333HOPatWqJafTqZiYGG3evNm9/G9/+5tatmwph8OhBg0a6LXXXvOoJzs7W/fff78CAgLUsGFDvf/++0VqzsnJ0aOPPqrg4GA5nU5169ZN27dvL+NXBkBZ4sgSAK+VnJys+fPna86cOWratKnWrl2rX/7ylwoODnb3GT9+vN544w2FhoZq0qRJuv/++7V37175+fkVWd+gQYPUrl07zZ49W9WqVdO2bdvc/dLS0vTwww/rxRdfVP/+/bV+/Xr99re/VZ06dTR06FBJ0tChQ3X06FGtXr1afn5+evzxx5Wdne3xHD//+c8VEBCgTz/9VIGBgXrnnXeUkJCgvXv3qnbt2uX3YgEovRv+Kl4AqAAXL140NWvWNOvXr/doHz58uBk4cKD7W9wXLlzoXnby5EkTEBBgFi1aZIwx5r333jOBgYHu5bVq1TJz584t9vl+8YtfmHvvvdejbfz48aZFixbGGGPS09ONJLNx40b38t27dxtJZvr06cYYY7788kvjdDqLfBN848aNzTvvvHN9LwCAm4YjSwC80v79+3X+/Hnde++9Hu0FBQVq166d++f4+Hj3v2vXrq3mzZtr9+7dxa5z7NixevTRR/XXv/5ViYmJ+vnPf67GjRtLknbv3q0+ffp49O/SpYtmzJihy5cva/fu3apevbpiYmLcy6Oiooqc5jt79qzq1KnjsZ4LFy7owIED1/cCALhpCEsAvNLZs2clSUuXLlX9+vU9ljkcjlKFjxdffFG/+MUvtHTpUn366aeaMmWKFi5cqAceeKDMar7tttu0Zs2aIsvK+xYGAEqPsATAK7Vo0UIOh0MZGRnq2rVrkeVXwtJXX32liIgISdLp06e1d+9eRUdHX3W9zZo1U7NmzfTUU09p4MCBeu+99/TAAw8oOjpa69at8+i7bt06NWvWTNWqVVNUVJQuXbqktLQ0dezYUZKUnp6unJwcd//27dsrMzNT1atXV4MGDW7wFQBwsxCWAHilWrVq6emnn9ZTTz0ll8ulO++8U7m5uVq3bp2cTqciIyMlSVOnTlWdOnUUEhKi5557TnXr1lXfvn2LrO/ChQsaP368HnroITVs2FDfffedNm3apH79+kmSxo0bp44dO+rll19W//79lZqaqpkzZ2rWrFmSpObNm6tHjx769a9/rdmzZ6t69ep68sknPW5NkJiYqPj4ePXt21d/+MMf1KxZMx09elRLly7VAw88oA4dOpT/Cwfg+lX0RVMAUFoul8vMmDHDNG/e3Pj5+Zng4GCTlJRkvvjiC/cF3v/6179My5Ytjb+/v4mNjTXbt293j//hBd75+flmwIABJjw83Pj7+5uwsDAzevRoc+HCBXf/jz76yLRo0cL4+fmZiIgIM23aNI96jh07Znr16mUcDoeJiIgw8+bNM5GRke4LvI0xJi8vz4wZM8aEhYUZPz8/Ex4ebgYNGmQyMjLK9bUCUHo+xhhT0YENAMramjVrdM899+j06dNcDwTghnBTSgAAAAvCEgAAgAWn4QAAACw4sgQAAGBBWAIAALAgLAEAAFgQlgAAACwISwAAABaEJQAAAAvCEgAAgAVhCQAAwIKwBAAAYPH/AOuCH2CnN12tAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Error",
     "evalue": "Invalid render mode `None`. Supported modes: `human`, `rgb_array`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m agent\u001b[38;5;241m.\u001b[39mplot(info_)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Run a test\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Cours\\UiS\\RL\\Project\\reinforcement-learning\\a2c.py:67\u001b[0m, in \u001b[0;36mA2C.test\u001b[1;34m(self, render)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# If render is true, renders the game to screen\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m render:\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Calculates the probs. for the actions given a state\u001b[39;00m\n\u001b[0;32m     69\u001b[0m policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\n\u001b[0;32m     70\u001b[0m     state_)\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[1;32mc:\\Cours\\UiS\\RL\\Project\\reinforcement-learning\\venv\\lib\\site-packages\\gymnasium\\wrappers\\common.py:409\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is an intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    408\u001b[0m     )\n\u001b[1;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Cours\\UiS\\RL\\Project\\reinforcement-learning\\venv\\lib\\site-packages\\gymnasium\\core.py:332\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Cours\\UiS\\RL\\Project\\reinforcement-learning\\venv\\lib\\site-packages\\gymnasium\\wrappers\\common.py:301\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_render \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_render \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_render_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Cours\\UiS\\RL\\Project\\reinforcement-learning\\venv\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:361\u001b[0m, in \u001b[0;36menv_render_passive_checker\u001b[1;34m(env)\u001b[0m\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01min\u001b[39;00m render_modes, (\n\u001b[0;32m    357\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe environment was initialized successfully however with an unsupported render mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRender mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, modes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrender_modes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         )\n\u001b[1;32m--> 361\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     _check_render_return(env\u001b[38;5;241m.\u001b[39mrender_mode, result)\n",
      "File \u001b[1;32mc:\\Cours\\UiS\\RL\\Project\\reinforcement-learning\\venv\\lib\\site-packages\\ale_py\\env.py:313\u001b[0m, in \u001b[0;36mAtariEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 313\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mError(\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid render mode `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported modes: `human`, `rgb_array`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    316\u001b[0m     )\n",
      "\u001b[1;31mError\u001b[0m: Invalid render mode `None`. Supported modes: `human`, `rgb_array`."
     ]
    }
   ],
   "source": [
    "# Instantiate the agent class.\n",
    "agent = A2CBatch(env)\n",
    "# Train the agent\n",
    "info = agent.train(epochs=2000)\n",
    "# Convert to an numpy array with epochs at axis=0 and scores at axis=1\n",
    "info_ = np.array(list(info.items()))\n",
    "# Plot the scores\n",
    "agent.plot(info_)\n",
    "# Run a test\n",
    "agent.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
